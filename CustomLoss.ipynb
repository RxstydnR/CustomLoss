{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9d929c066c7f>:9: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️　Be sure to use **tensorflow.keras**, unless direct tensorflow is not available, and you can probably see any errors.<br>\n",
    "Don't mix up **tf.keras** and **keras**.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make your own Loss Function.\n",
    "\n",
    "Keras provides us a couple of ways to make Loss Fuction, but here main two ways will be explained.\n",
    "1. `Function` (**Easy** way, but only if it's **simple one.**)\n",
    "2. `Class` (You can make **anything complex**. Note that this is **not** so difficult.)\n",
    "\n",
    "This notebook especially focuses on **Image Loss function**.  \n",
    "\n",
    "ex) Reconstruction Loss, VGG Loss(Content Loss, Style Loss)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Function\n",
    "`Function` type get **2** arguments.\n",
    "- ***y_true* : Label of data.**  ex) Ground Truth image, numeric label, etc...\n",
    "- ***y_pred* : Model prediction.**  This is the same type of *y_true*.\n",
    "\n",
    "If your model is trained with image data, the shape of *y_true* and *y_pred* will be **(Batchsize, Imagesize,Imagesize, Channel)**.<br>\n",
    "Of course you know **loss function gets batch data** because any model is trained with batch data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-1. Simple MSE Loss\n",
    "$$\n",
    "Loss = \\frac{1}{N} |y_{true}-y_{pred}|^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mse(y_true, y_pred):\n",
    "    loss = tf.reduce_mean(tf.math.abs(y_true - y_pred)**2)\n",
    "    # loss = K.mean(K.square(y_true - y_pred)) ← This is another option.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding function in Loss function is possible.<br>\n",
    "You can write simple MSE Loss like this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mse_2(y_true, y_pred):\n",
    "    def subtract(x,y):\n",
    "        return tf.math.abs(x-y)\n",
    "    def square(x):\n",
    "        return x**2\n",
    "    def reduce_mean(x):\n",
    "        return tf.reduce_mean(x)\n",
    "    loss = subtract(y_true, y_pred)\n",
    "    loss = square(loss)\n",
    "    loss = reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you **pass arguments** to loss function before training, loss function have to be **wrapped** another function like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_simple_loss(args):\n",
    "    alpha = args[0]\n",
    "    beta = args[1]\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Loss function that accepts (y_true, y_pred) must be placed inside.\n",
    "        loss = tf.reduce_mean(tf.math.abs((y_true - y_pred)**2))\n",
    "        return loss # This return value is referenced to the following overall return value.\n",
    "    return loss_function\n",
    "\n",
    "func_obj = bias_simple_loss([2,5]) \n",
    "# you set func_obj to fit\n",
    "# ex) model.fit(x,y,loss=func_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-2. VGG Loss\n",
    "Defined as VGG Loss, there are many different types such as **Content Loss, Style Loss, etc**.<br>\n",
    "The definition depends on the methodology which you are going to use.<br>\n",
    "Therefore, with reference to the following example and papers, you can customize it.\n",
    "\n",
    "**Below, a simple example of VGG Loss using one intermediate layer in VGG19.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "# image_shape must be the size of image used for training.\n",
    "vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
    "\n",
    "# Make VGG19 not train\n",
    "vgg19.trainable = False\n",
    "for l in vgg19.layers:\n",
    "    l.trainable = False\n",
    "    \n",
    "# \"block5_conv4\" is used as intermediate layer to get features.\n",
    "model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
    "model.trainable = False\n",
    "\n",
    "def vgg_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(model(y_true) - model(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what layers are in VGG19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "relu block1_conv1\n",
      "relu block1_conv2\n",
      "block1_pool\n",
      "relu block2_conv1\n",
      "relu block2_conv2\n",
      "block2_pool\n",
      "relu block3_conv1\n",
      "relu block3_conv2\n",
      "relu block3_conv3\n",
      "relu block3_conv4\n",
      "block3_pool\n",
      "relu block4_conv1\n",
      "relu block4_conv2\n",
      "relu block4_conv3\n",
      "relu block4_conv4\n",
      "block4_pool\n",
      "relu block5_conv1\n",
      "relu block5_conv2\n",
      "relu block5_conv3\n",
      "relu block5_conv4\n",
      "block5_pool\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vgg19.layers)):\n",
    "    try:\n",
    "        print(vgg19.layers[i].get_config()[\"activation\"],model.layers[i].get_config()[\"name\"])\n",
    "    except:\n",
    "        print(vgg19.layers[i].get_config()[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of Style Loss using Gram matrix.**<br>\n",
    "This loss is just for an example but not useful and practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(y_true,y_pred):\n",
    "    \n",
    "    shape = K.shape(y_true)\n",
    "    B, C, H, W = shape[0], shape[1], shape[2], shape[3]\n",
    "    size = H * W\n",
    "\n",
    "    def gram_matrix(x):\n",
    "        assert K.ndim(x) == 4, 'Input tensor should be a 4d (B, H, W, C) tensor'\n",
    "        assert K.image_data_format() == 'channels_last', \"Please use channels-last format\"        \n",
    "\n",
    "        x = K.permute_dimensions(x, (0, 3, 1, 2))\n",
    "        features = K.reshape(x, K.stack([B, C, H*W])) # Permute channels and get resulting shape\n",
    "        gram = K.batch_dot(features, features, axes=2) # Reshape x and do batch dot product\n",
    "        # gram = gram / K.cast(C * H * W, x.dtype) # Normalize with channels, height and width\n",
    "        return gram\n",
    "    \n",
    "    y_true_gram = gram_matrix(y_true)\n",
    "    y_pred_gram = gram_matrix(y_pred)\n",
    "    # return K.sum(K.square(y_true_gram - y_pred_gram)) / K.cast(size*B*C, dtype=tf.float32)\n",
    "    return K.sum(K.abs(y_true_gram - y_pred_gram)) / K.cast(size*B*C, dtype=tf.float32)\n",
    "\n",
    "# For debug\n",
    "# style_loss(K.variable(X_train),K.variable(X_train[::-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of VGG Loss using multi intermediate layers in VGG19.**\n",
    "\n",
    "*This is so complex loss fuuction that we need to use `Class` Loss function method instead of function type.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19 \n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Feature Extractor\n",
    "vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
    "vgg19.trainable = False\n",
    "\n",
    "# Intermediate layers in VGG19.\n",
    "target_layers = [\n",
    "    'block1_conv2', \n",
    "    'block2_conv2', \n",
    "    'block3_conv4', \n",
    "    'block4_conv4', \n",
    "    'block5_conv4'\n",
    "]\n",
    "# For weighting outputs of intermediate layers.\n",
    "style_weights = np.array([1,1,1,1,1])\n",
    "\n",
    "vgg19.outputs = [vgg19.get_layer(target_layers[i]).output for i in range(len(target_layers))]\n",
    "style_model = Model(inputs=vgg19.input, outputs=vgg19.outputs)\n",
    "style_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_style_loss(y_true,y_pred): # VGG Style Loss (Multiple gram matrix)\n",
    "\n",
    "    def style_loss(y_true_style, y_pred_style):\n",
    "\n",
    "        shape = K.shape(y_true_style)\n",
    "        B, H, W, C = shape[0], shape[1], shape[2], shape[3]\n",
    "        size = H * W\n",
    "\n",
    "        def gram_matrix(x):\n",
    "            assert K.ndim(x) == 4, 'Input tensor should be a 4d (B, H, W, C) tensor'\n",
    "            assert K.image_data_format() == 'channels_last', \"Please use channels-last format\"        \n",
    "\n",
    "            x = K.permute_dimensions(x, (0, 3, 1, 2)) # (B, H, W, C) → (B, C, H, W)\n",
    "            features = K.reshape(x, K.stack([B, C, H*W])) # Permute channels and get resulting shape\n",
    "            gram = K.batch_dot(features, features, axes=2) # Reshape x and do batch dot product\n",
    "            return gram/K.cast(size*C, dtype=tf.float32)\n",
    "\n",
    "        y_true_gram = gram_matrix(y_true_style)\n",
    "        y_pred_gram = gram_matrix(y_pred_style)\n",
    "\n",
    "        return K.sum(K.square(y_true_gram - y_pred_gram)) / K.cast(size*C, dtype=tf.float32) \n",
    "\n",
    "    y_true_styles = style_model(y_true)\n",
    "    y_pred_styles = style_model(y_pred)\n",
    "    \n",
    "    loss = K.zeros(shape=()) # Initialize the loss\n",
    "    \n",
    "    # sum up each style loss\n",
    "    for y_true_style,y_pred_style,style_weight in zip(y_true_styles,y_pred_styles,style_weights):\n",
    "        add_loss = K.variable(style_weight) * style_loss(y_true_style,y_pred_style)\n",
    "        loss = K.update_add(loss, add_loss)\n",
    "\n",
    "    return K.variable(loss)\n",
    "\n",
    "# For debug\n",
    "# multiple_style_loss(K.variable(x_train),K.variable(x_train[::-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Class\n",
    "`Class` type consists of at least 2 functions.<br>\n",
    "(This is common to classes written in pythons.)\n",
    "\n",
    "1. **`__init__` (constructor)** : set instance parameter\n",
    "2. **`call`** method : this will be called to **calculate loss** at every batch training.\n",
    "\n",
    "\n",
    "**`call`** method get **2** arguments. Same as `Function` type.\n",
    "\n",
    "- ***y_true* : Label of data.**  \n",
    "- ***y_pred* : Model prediction.**  \n",
    "\n",
    "If your model is trained with image data, the shape of *y_true* and *y_pred* will be **(Batchsize, Imagesize,Imagesize, Channel)**.<br>\n",
    "Of course you know **loss function gets batch data** because any model is trained with batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass CustomLoss(tf.keras.losses.Loss):\\n\\n    def __init__(self, args):\\n        super().__init__()\\n\\n    def call(self, y_true, y_pred):\\n        # The process of calculating the loss\\n        return loss\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # The process of calculating the loss\n",
    "        return loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \n",
    "##### \n",
    "##### 2-1 Simple Loss function Class.\n",
    "*Let's rewrite **style loss** in `Class` type.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
    "        vgg19.trainable = False\n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
    "        model.trainable = False\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return K.mean(K.square(model(y_true) - model(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of VGG Loss using multi intermediate layers in VGG19.**\n",
    "\n",
    "*Let's rewrite **multiple style loss** in `Class` type.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VGG19Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
    "        vgg19.trainable = False\n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "\n",
    "        self.base_model = Model(inputs=vgg19.input, outputs=vgg19.get_layer(\"block4_conv2\").output)\n",
    "        self.base_model.trainable = False\n",
    "\n",
    "        target_layers = ['block1_conv2', 'block2_conv2', 'block3_conv4', 'block4_conv4', 'block5_conv4']\n",
    "        \n",
    "        # Feature Extractor\n",
    "        vgg19.outputs = [vgg19.get_layer(target_layers[i]).output for i in range(len(target_layers))]\n",
    "        self.style_model = Model(inputs=vgg19.input, outputs=vgg19.outputs)\n",
    "        self.style_model.trainable = False\n",
    "\n",
    "        self.style_weights = np.array([1,1,1,1,1])      \n",
    "\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        def style_loss(y_true_style, y_pred_style):\n",
    "\n",
    "            shape = K.shape(y_true_style)\n",
    "            B, H, W, C = shape[0], shape[1], shape[2], shape[3]\n",
    "            size = H * W\n",
    "\n",
    "            def gram_matrix(x):\n",
    "                assert K.ndim(x) == 4, 'Input tensor should be a 4d (B, H, W, C) tensor'\n",
    "                assert K.image_data_format() == 'channels_last', \"Please use channels-last format\"        \n",
    "\n",
    "                x = K.permute_dimensions(x, (0, 3, 1, 2)) # (B, H, W, C) → (B, C, H, W)\n",
    "                features = K.reshape(x, K.stack([B, C, H*W])) # Permute channels and get resulting shape\n",
    "                gram = K.batch_dot(features, features, axes=2) # Reshape x and do batch dot product\n",
    "                return gram/K.cast(size*C, dtype=tf.float32)\n",
    "\n",
    "            y_true_gram = gram_matrix(y_true_style)\n",
    "            y_pred_gram = gram_matrix(y_pred_style)\n",
    "            \n",
    "            return K.sum(K.square(y_true_gram - y_pred_gram)) / K.cast(size*C, dtype=tf.float32) \n",
    "\n",
    "        y_true_styles = self.style_model(y_true)\n",
    "        y_pred_styles = self.style_model(y_pred)\n",
    "\n",
    "        loss = K.zeros(shape=()) # Initialize the loss\n",
    "\n",
    "        # sum up each style loss\n",
    "        for y_true_style,y_pred_style,style_weight in zip(y_true_styles,y_pred_styles,self.style_weights):\n",
    "            add_loss = K.variable(style_weight) * style_loss(y_true_style,y_pred_style)\n",
    "            loss = K.update_add(loss, add_loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1 Multi Loss function Class.\n",
    "\n",
    "It's already so easy to **combine multiple losses.**<br>\n",
    "This is example to combine three losses below in one class.\n",
    "\n",
    "- reconst_loss(): # MSE Loss\n",
    "- content_loss(): # VGG Loss\n",
    "- multiple_style_loss(): # VGG Style Loss (Multiple gram matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CombineLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
    "        vgg19.trainable = False\n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "\n",
    "        ''' VGG Loss (Content Loss) '''        \n",
    "        self.base_model = Model(inputs=vgg19.input, outputs=vgg19.get_layer(\"block4_conv2\").output)\n",
    "        self.base_model.trainable = False\n",
    "\n",
    "        ''' Texture Loss '''\n",
    "        target_layers = ['block1_conv2', 'block2_conv2', 'block3_conv4', 'block4_conv4', 'block5_conv4']\n",
    "        \n",
    "        vgg19.outputs = [vgg19.get_layer(target_layers[i]).output for i in range(len(target_layers))]\n",
    "        self.style_model = Model(inputs=vgg19.input, outputs=vgg19.outputs)\n",
    "        self.style_model.trainable = False\n",
    "\n",
    "        self.style_weights = np.array([1,1,1,1,1])*(10**2)\n",
    "\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        \n",
    "        def reconst_loss(): # MSE Loss\n",
    "            return K.mean(K.square(y_true - y_pred))\n",
    "\n",
    "        def content_loss(): # VGG Loss\n",
    "            vgg_true_output = self.base_model(y_true)\n",
    "            vgg_pred_output = self.base_model(y_pred)\n",
    "            return K.mean(K.square(vgg_true_output - vgg_pred_output))\n",
    "\n",
    "        def multiple_style_loss(): # VGG Style Loss (Multiple gram matrix)\n",
    "            def style_loss(y_true_style, y_pred_style):\n",
    "\n",
    "                shape = K.shape(y_true_style)\n",
    "                B, H, W, C = shape[0], shape[1], shape[2], shape[3]\n",
    "                size = H * W\n",
    "\n",
    "                def gram_matrix(x):\n",
    "                    assert K.ndim(x) == 4, 'Input tensor should be a 4d (B, H, W, C) tensor'\n",
    "                    assert K.image_data_format() == 'channels_last', \"Please use channels-last format\"        \n",
    "\n",
    "                    x = K.permute_dimensions(x, (0, 3, 1, 2)) # (B, H, W, C) → (B, C, H, W)\n",
    "                    features = K.reshape(x, K.stack([B, C, H*W])) # Permute channels and get resulting shape\n",
    "                    gram = K.batch_dot(features, features, axes=2) # Reshape x and do batch dot product\n",
    "                    return gram/K.cast(size*C, dtype=tf.float32)\n",
    "\n",
    "                y_true_gram = gram_matrix(y_true_style)\n",
    "                y_pred_gram = gram_matrix(y_pred_style)\n",
    "\n",
    "                return K.sum(K.square(y_true_gram - y_pred_gram)) / K.cast(size*C, dtype=tf.float32) \n",
    "\n",
    "            y_true_styles = self.style_model(y_true)\n",
    "            y_pred_styles = self.style_model(y_pred)\n",
    "\n",
    "            loss = K.zeros(shape=()) # Initialize the loss\n",
    "            \n",
    "            # sum up each style loss\n",
    "            for y_true_style,y_pred_style,style_weight in zip(y_true_styles,y_pred_styles,self.style_weights):\n",
    "                add_loss = K.variable(style_weight) * style_loss(y_true_style,y_pred_style)\n",
    "                loss = K.update_add(loss, add_loss)\n",
    "\n",
    "            return loss\n",
    "        \n",
    "        # Loss function\n",
    "        Loss = [\n",
    "                content_loss(),\n",
    "                reconst_loss(),\n",
    "                multiple_style_loss()\n",
    "        ]\n",
    "        Loss = K.sum(Loss)\n",
    "\n",
    "        return Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Try Loss Function.\n",
    "\n",
    "Explaination has been over here 🎉<br>\n",
    "Try any loss function above with AE(AutoEncoder) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "    l1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(input_img)\n",
    "    l2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l1)\n",
    "    l3 = tf.keras.layers.MaxPool2D(padding='same')(l2)\n",
    "    l4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l3)\n",
    "    l5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l4)\n",
    "    l6 = tf.keras.layers.MaxPool2D(padding='same')(l5)\n",
    "    l7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l6)\n",
    "    l8 = tf.keras.layers.UpSampling2D()(l7)\n",
    "    l9 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l8)\n",
    "    l10 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l9)\n",
    "    l11 = tf.keras.layers.add([l10, l5])\n",
    "    l12 = tf.keras.layers.UpSampling2D()(l11)\n",
    "    l13 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l12)\n",
    "    l14 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l13)\n",
    "    l15 = tf.keras.layers.add([l14, l2])\n",
    "    \n",
    "    encoder = tf.keras.models.Model(inputs=(input_img), outputs=l7)\n",
    "    decoded_image = tf.keras.layers.Conv2D(3, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(l15)\n",
    "    autoencoder = tf.keras.models.Model(inputs=(input_img), outputs=decoded_image)\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 174ms/step - loss: 11345.5479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8109286c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "\n",
    "model = build_model()\n",
    "################################################\n",
    " # loss = [Name of above losses or one you make]\n",
    "################################################\n",
    "model.compile(optimizer='adam', loss=CombineLoss())\n",
    "\n",
    "# Auto Encoder image reconstruction training\n",
    "model.fit(\n",
    "    np.array(x_train)[:10],\n",
    "    np.array(x_train)[:10],\n",
    "    epochs=1,\n",
    "    batch_size=2,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### References on Loss Function\n",
    "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "- [Shape preserving loss](https://github.com/ZengqiangYan/Shape-preservingLoss/blob/master/Loss.py)\n",
    "- [Texture GAN](https://github.com/janesjanes/Pytorch-TextureGAN)\n",
    "- [Style Loss](https://blog.shikoan.com/style-loss/)\n",
    "\n",
    "#### References on Inplementation of Loss Function\n",
    "- [tf.Keras Backend](https://www.tensorflow.org/api_docs/python/tf/keras/backend?hl=ja)\n",
    "- [TensorFlow, KerasでVGG16などの学習済みモデルを利用](https://note.nkmk.me/python-tensorflow-keras-applications-pretrained-models/)\n",
    "- [Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models](https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0)\n",
    "- [Loss Function Classの作成例](https://memo.sugyan.com/entry/2020/02/16/220750)\n",
    "- [kerasで自作損失関数を実装したい](https://teratail.com/questions/185516)\n",
    "- [Kerasで損失関数に複数の変数を渡す方法](https://blog.shikoan.com/keras-loss-function-multiple-arguments/)  \n",
    "→ Custom Loss function usually receive only (y_true and y_pred).  \n",
    "→ Q. When you get loss function to get other paramerters.  \n",
    "→ A. Let's wrap the loss function with another function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Memo**\n",
    "\n",
    "`<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=197785280.0>`\n",
    "\n",
    "→ 'UnreadVariable' is handled dynamically when Tensor includes a calculation with just a number or so. <br>\n",
    "→ The result is a Tensor form, but is not actually Tensor.<br>\n",
    "→ Not necessary to care about here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Thanks😎"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
